#!/usr/bin/env ruby
# frozen_string_literal: true

# An RSpec wrapper that cuts down on the clutter
# and makes it easier to re-run failing tests.
#
# run:
#   rtest --help
# to see full usage options.
#
#
require 'json'
require 'open3'
require 'optparse'
require 'tempfile'
require 'set'

# in case you use byebug or binding.pry
require 'expect'
require 'io/wait'
require 'pty'
require 'stringio'

# require all the rtest classes and modules
# Dir[File.join(__dir__, 'lib', 'rtest', '*.rb')].each { |file| require file }
libs = File.join(__dir__, 'lib', 'rtest', '*.rb')
Dir[libs].sort.each { |file| require file }

USAGE = <<~EOL
    rtest is a convenience tool to make life easier when dealing with RSpec.

    Output is limited to actionable details about failing tests and
    just enough to get you to the right place to fix them.

    rtest also has a number of options for making it trivial to rerun
    failing tests without needing to specify paths and line numbers.

    Version: VERSION_NUMBER_HERE

    USAGE:

    rtest [-h | --help]
      display these usage instructions

    rtest
      shows you numbered list of last test failures (if any)

    rtest all
      run _all_ rspect tests

    rtest last_file
      finds the last file that had a problem
      and runs all the tests in it.

    rtest <n>
      re-run a specific failure from the last test
      as identified by its number

    rtest <n> +/-<x>
      re-run a specific failure from the last test
      as identified by its number
      BUT offset the line number of the test +/- x
      (useful if you've added or removed lines above it)

      Ex. rtest 5 +2
      runs example number 5 but specifes a line number 2 greater
      than the initial failure reported.

    rtest <path_to/file_spec.rb>
      run a specific spec and captures failures (if any)
      you can run it with the optional line number syntax too
      E.g. rtest path_to/file_spec.rb
        or rtest path_to/file_spec.rb:32

    rtest kill <number>
      removes the test with the specified number from the
      list of past failures

    rtest kill <number>-<number>
      removes the tests with numbers within the specified
      range of past failure numbers (inclusive).

    rtest rerun [<n>|<range>]
      by itself this runs all the past failures

      if you pass in a number, or a range:
      E.g. "1" or "3-5" it will rerun the specified
      tests. This behavior is the same as
      calling rtest with just the numbers.

    rtest file <number>
      outputs the rspec file path from the test with that number
      Ex.
      path/to/failing_spec

    rtest [files | --files]
      outputs a list of all the files+line numbers of failing tests
      Ex:
      path/to/failing_spec:43
      path/to/failing_spec:68
      path/to/other_spec:44

    rtest [-s | --shortened]
      Can be combined with out options.
      Truncates file paths to fit the screen width if possible.
      Guaranteed to always leave the basename intact.

    rtest [--rspec=NUMBER]
      outputs the rspec command required to rerun the
      specified failure in rspec.

      In fish shell, for example, you could say
        eval (rtest --rspec=4)
      to run failure #4 in rspec directly.

    VERBOSE MODE

    rtest [-v|--verbose] <any prior command>
      instead of "marching ants" verbose mode will print out the names
      of classes under test as their respective tests are being run.

EOL
USAGE.freeze

# NOTE: How to Capture Test Output
# bundle exec rspec foo_spec.rb | sd "\r\n" "\n" > path/to/test_data/test_N.txt
# rtest foo_spec.rb | ansifilter | sed -e "s/^Running .*//" | sd "^\.+\n" "" > path/to/test_data/test_N_expected_output.txt

@options = {
  shortened_paths: false,
  verbose: false,
  debug: false,
  auto_verbose_seconds: 0,
  rspec: false
}

options_parser = OptionParser.new do |parser|
  parser.banner = 'Usage: example.rb [options]'

  parser.on('-v', '--verbose', 'Run verbosely') do |v|
    @options[:verbose] = v
  end

  parser.on('-s', '--shortened', 'Truncate paths to fit screen width') do
    @options[:shortened_paths] = true
  end

  parser.on('-tTEST_FILE', '--test=TEST_FILE', 'path to test file') do |tf|
    @options[:test_file] = tf
    @options[:expected_output_file] = tf.sub(/\.txt$/, '_expected_output.txt')
  end

  parser.on('-aSECONDS', '--auto-verbose=SECONDS', 'Switch to verbose mode if run takes more than SECONDS') do |s|
    @options[:auto_verbose_seconds] = s.to_i
  end

  parser.on('--rspec=NUMBER', 'outputs the command to run the specified test in rspec') do |number|
    if /^\d+$/.match(number)
      @options[:rspec] = number.to_i
    elsif number == 'all'
      @options[:rspec] = 'all'
    else
      raise(OptionParser::InvalidArgument, "#{number}: is not a valid argument for --rspec")
    end
  end
  # ðŸ¤« ssssh secret. Just for us rtest devs.
  parser.on('--fspec',
            'outputs the command to run the specified test in rspec with our custom formatter') do
    @options[:fspec] = true
  end

  parser.on('-d', '--debug', 'Debug mode') do
    @options[:debug] = true
  end

  parser.on('--files', 'alternate way to specify listing files') do
    @options[:files] = true
  end

  parser.on('-h', '--help') do
    puts USAGE
    exit 0
  end
end

numeric_options = ARGV.select { |o| /^-?\d+$/.match(o) }
begin
  options_parser.parse(ARGV.reject { |o| /^-?\d+$/.match(o) })
rescue OptionParser::MissingArgument => e
  puts "That option requires an argument: \n\t#{e.message.sub('missing argument: ', '')}\n\n"
  puts '------------------------------------------'
  puts USAGE
  exit 75 # EX_TEMPFAIL (user input)
rescue OptionParser::InvalidOption => e
  puts "That is not a supported argument: \n\t#{e.message.sub('invalid option: ', '')}\n\n"
  puts '------------------------------------------'
  puts USAGE
  exit 75 # EX_TEMPFAIL (user input)
end
REMAINING_ARGS = ARGV.reject { |o| /^-\w+\S*$|^--\w+$|^--\w+(?:=\S+)$/.match(o) } + numeric_options
OPTIONS = @options

VERBOSE = OPTIONS[:verbose]
AUTO_VERBOSE = if (OPTIONS[:auto_verbose_seconds]).positive?
                 OPTIONS[:auto_verbose_seconds]
               else
                 # "".to_i == 0
                 ENV['RTEST_AUTO_VERBOSE'].to_i
               end
TEST_MODE = OPTIONS.key? :test_file
VERBOSE_TEST = TEST_MODE && VERBOSE
puts 'Running in Verbose Test mode.' if VERBOSE_TEST
DEBUG = OPTIONS[:debug]

SCREEN_WIDTH = (ENV['COLUMNS'] || `tput cols`.chomp || 80).to_i
INPUT = REMAINING_ARGS.size.positive? ? REMAINING_ARGS.shift : nil

START = Time.now.to_i

def validate_failure_numbers(numbers, valid_failure_numbers)
  numbers = Array(numbers)
  if (numbers & valid_failure_numbers).size == numbers.size
    return true
  else
    invalid_failure_number_error(valid_failure_numbers)
  end
end
def invalid_failure_number_error(valid_failure_numbers)
  if valid_failure_numbers.size.positive?
    puts "One or more of the numbers suplied are invalid"
    if valid_failure_numbers.size == valid_failure_numbers.last.to_i
      puts "Please specify a number between #{valid_failure_numbers.first} & #{valid_failure_numbers.last}"
    else
      puts "Please specify one of the following numbers #{valid_failure_numbers.join(", ")}"
    end
  else
    puts "There are no known failures"
  end
    exit 75 # EX_TEMPFAIL (user input)
end

# returns a Rtest::RunLog

def output_run_results(run_data)
  if run_data.failures.size.positive?
    Rtest::FailurePrinter.display_failures(run_data.failures)
  else
    puts NO_FAILURES_TEXT
  end
end

def display_run_log(run_log)
  if run_log.has_failures?
    Rtest::FailurePrinter.display_failures(run_log.failures)
  else
    puts 'No past failure data. Please run a spec through me.'
  end
end

def display_files(past_run_data)
  past_run_data.failures.each do |failure|
    puts failure.rspec_arg.to_s
  end
end

def is_arg_range(arg)
  /^\d+-\d+?$/.match(arg)
end

def range_arg_to_array(arg)
  arg.split('-').map(&:to_i)
end

# this returns true if there is NO point
# in loading the existing data file
def input_denotes_fresh_run?(input)
  return true if input == 'all'
  return true if /.*_spec.rb(?::\d+)?$/.match(input)

  false
end

# -------------------------

past_run_data = Rtest::RunLog.new

if File.exist?(PAST_RUN_FILENAME) && !TEST_MODE && !input_denotes_fresh_run?(INPUT)
  past_run_data = Rtest::RunLog.from_file(PAST_RUN_FILENAME)
end

if INPUT.nil? && !OPTIONS[:rspec]
  display_run_log(past_run_data)
  puts NO_TESTS_RUN_TEXT
elsif /.*_spec.rb(:\d+)?$/.match(INPUT) \
  || INPUT == 'all' \
  || INPUT == 'last_file' \
  || %r{\S+/$}.match(INPUT) # ends with a slash, prolly a directory
  if INPUT != 'all' && INPUT != 'last_file'
    unless File.exist?(INPUT.sub(/:\d+$/, ''))
      warn("Could not find specified file or directory:\n#{INPUT}")
      warn('Please try again with a valid path.')
      exit 64 # EX_USAGE
    end
    if !OPTIONS[:fspec] && !OPTIONS[:rspec]
      puts "Running specs in #{INPUT}\n"
      # must be a spec file
      updated_run_data = Rtest::Runner.run_and_display_this(INPUT, true)
    elsif OPTIONS[:rspec]
      puts Rtest::Runner.rspec_command(INPUT)
      exit 0
    else
      puts Rtest::Runner.fspec_command(INPUT)
      exit 0
    end
  elsif INPUT == 'last_file'
    unless past_run_data.has_failures?
      puts 'No file data from last run'
      exit 64 # EX_USAGE
    end
    last_file = past_run_data.last_file
    if last_file.nil?
      warn('ðŸ¤¨ Unable to find spec file amongst past failures. ')
      exit 1
    end
    if ! OPTIONS[:rspec]
      puts "Running #{last_file}...\n"
      updated_run_data = Rtest::Rerunner.new(past_run_data).rerun_last_file(persist: true)
      # rerunner will take care of mentioning fixed tests
    else
      puts Rtest::Runner.rspec(last_file)
      exit 0
    end
  elsif INPUT == 'all'
    if !OPTIONS[:fspec] && !OPTIONS[:rspec]
      puts "Running ALL specs...\n"
      updated_run_data = Rtest::Runner.run_and_display_this('', true)
    elsif OPTIONS[:rspec]
      puts Rtest::Runner.rspec_command('')
      exit 0
    else
      puts Rtest::Runner.fspec_command('')
      exit 0
    end
  end
  puts NO_FAILURES_TEXT unless updated_run_data.has_failures?
elsif /^\d+$/.match(INPUT) || OPTIONS[:rspec]
  failure_number = OPTIONS[:rspec] || INPUT.to_i
  offset = REMAINING_ARGS.size.positive? ? REMAINING_ARGS[0].to_i : 0
  # NOTE: display happens during rerun
  failure = past_run_data.get_failure_by_number(failure_number)
  if !failure.nil?
    failure.offset = offset
    if !OPTIONS[:rspec]
      Rtest::Rerunner.new(past_run_data).rerun(failure_number, persist: true)
    else
      # we can't run it ourselves or we'll hang on byebug or
      # binding.pry lines
      #
      # we _could_ do it the way we do the other interactive stuff
      # but the idea here was to make it trivial to rerun something in
      # rspec directly
      if !OPTIONS[:fspec]
        puts Rtest::Runner.rspec_command(failure.rspec_arg)
      else
        puts Rtest::Runner.fspec_command(failure.rspec_arg)
      end
      exit 0
    end
  else
    invalid_failure_number_error(past_run_data.failure_numbers)
  end
  # rerunner will take care of mentioning fixed tests
elsif INPUT == 'rerun'
  unless past_run_data.has_failures?
    puts 'No past failures found to rerun.'
    exit 0
  end
  if REMAINING_ARGS.size.positive? && REMAINING_ARGS[0].downcase != "all"
    next_arg = REMAINING_ARGS[0]
    if is_arg_range(next_arg)
      ints = range_arg_to_array(next_arg)
      puts "Rerunning #{ints.join('..')}"
      Rtest::Rerunner.new(past_run_data).rerun(ints, persist: true)
    elsif /^\d+$/.match(next_arg) && next_arg.to_i.positive?
      failure_number = next_arg.to_i
      validate_failure_numbers(failure_number, past_run_data.failure_numbers)
      puts "Rerunning #{next_arg.to_i}"

      Rtest::Rerunner.new(past_run_data).rerun(failure_number, persist: true)
    else
      warn('unexpected arguments passed to rerun.')
      warn('Run "rtest --help" to see usage instructions')
      exit 1
    end
  else
    Rtest::Rerunner.new(past_run_data).rerun_all(persist: true)
  end

elsif INPUT == 'kill' &&  /^\d+(-\d+)?$/.match(REMAINING_ARGS[0].to_s)
  if !is_arg_range(REMAINING_ARGS[0])
    indexes = Array(REMAINING_ARGS[0].to_i)
  else
    x, y = range_arg_to_array(REMAINING_ARGS[0])
    # If we work from highest to lowest we can
    # avoid complications resulting
    # from shortening an array while iterating over it

    indexes = if x < y
                (x..y).to_a.reverse
              elsif x == y
                [x]
              else
                (x..y).to_a
              end
  end
  validate_failure_numbers(indexes, past_run_data.failure_numbers)

  Rtest::Killer.kill_and_display(past_run_data, indexes)
elsif INPUT == 'file' &&  /^\d+$/.match(REMAINING_ARGS[0].to_s)
  number = REMAINING_ARGS[1].to_i
  failure = past_run_data.get_failure_by_number(number)
  if failure
    puts failure.spec_file_path
  else
    puts "Couldn't find failure numbered: #{number}"
    exit 75 # EX_TEMPFAIL (user input)
  end
elsif INPUT == 'files' || OPTIONS[:files]
  display_files(past_run_data)
elsif /\.rb$/.match(INPUT)
  warn "ðŸ›‘ That's a ruby file, but not an rspec (*_spec.rb) file."
  matches = `find . -name $(basename #{INPUT.gsub(/\.rb$/, '_spec.rb')})`.strip
  if matches != ''
    warn('Did you mean:')
    matches.split("\n").each do |match|
      warn "\t#{match}"
    end
  end
end
